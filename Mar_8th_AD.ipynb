{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMTT7HrHyomsFxKOSQKuZVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashwanthReddyKongara/LMS-Assignments/blob/main/Mar_8th_AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g96PN5GaKgvM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, LeakyReLU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10) # reproduction\n",
        "# The dimension of our random noise vector.\n",
        "random_dim = 100"
      ],
      "metadata": {
        "id": "qmMP5GOYNW3z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer():\n",
        "\n",
        "    return Adam(learning_rate=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "_bITJ8LjOB45"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator(optimizer):\n",
        "    generator = Sequential()\n",
        "    generator.add(Dense(256, input_dim=random_dim, \\\n",
        "            kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    generator.add(Dense(512))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    generator.add(Dense(1024))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    generator.add(Dense(784, activation='tanh'))\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return generator"
      ],
      "metadata": {
        "id": "8ZO36FFbOEKN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator(optimizer):\n",
        "\n",
        "    discriminator = Sequential()\n",
        "\n",
        "    discriminator.add(Dense(1024, input_dim=784, \\\n",
        "\n",
        "                kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(512))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(256))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return discriminator"
      ],
      "metadata": {
        "id": "uogATHzyOJ1p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
        "\n",
        "    # We initially set trainable to False since we only want to train either the\n",
        "\n",
        "    # generator or discriminator at a time\n",
        "\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    # gan input (noise) will be 100-dimensional vectors\n",
        "\n",
        "    gan_input = Input(shape=(random_dim,))\n",
        "\n",
        "    # the output of the generator (an image)\n",
        "\n",
        "    x = generator(gan_input)\n",
        "\n",
        "    # get the output of the discriminator (probability if the image is real or not)\n",
        "\n",
        "    gan_output = discriminator(x)\n",
        "\n",
        "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return gan"
      ],
      "metadata": {
        "id": "w61fpO8TQJ7-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), \\\n",
        "\n",
        "                          figsize=(10, 10)):\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
        "\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for i in range(generated_images.shape[0]):\n",
        "\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', \\\n",
        "\n",
        "                   cmap='gray_r')\n",
        "\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "DAbxviFEQLRa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def train(epochs=1, batch_size=128, random_dim=100):\n",
        "    # 1. Get the training and testing data\n",
        "    (x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "    # Normalize data to range [-1, 1] for better GAN performance\n",
        "    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "    x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n",
        "\n",
        "    batch_count = x_train.shape[0] // batch_size\n",
        "\n",
        "    # 2. Build GAN network\n",
        "    adam = get_optimizer()\n",
        "    generator = get_generator(adam)\n",
        "    discriminator = get_discriminator(adam)\n",
        "    gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
        "\n",
        "    # 3. Training loop\n",
        "    for e in range(1, epochs + 1):\n",
        "        print('-' * 15, f'Epoch {e}', '-' * 15)\n",
        "\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            # 4. Generate noise and get real images\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "            image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n",
        "\n",
        "            # 5. Generate fake images\n",
        "            generated_images = generator.predict(noise)\n",
        "            X = np.concatenate([image_batch, generated_images])\n",
        "\n",
        "            # 6. Create labels\n",
        "            y_dis = np.zeros(2 * batch_size)\n",
        "            y_dis[:batch_size] = 0.9  # Label smoothing\n",
        "\n",
        "            # 7. Train discriminator\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X, y_dis)\n",
        "\n",
        "            # 8. Train generator\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "            y_gen = np.ones(batch_size)\n",
        "\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "        # Save images at specific intervals\n",
        "        if e == 1 or e % 20 == 0:\n",
        "            plot_generated_images(e, generator)\n"
      ],
      "metadata": {
        "id": "gRIZksdFQ0E_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0vSqGWDTtfy"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}